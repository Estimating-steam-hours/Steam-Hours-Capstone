{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "358e9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Wrangle as w\n",
    "import os\n",
    "import modeling as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9deb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f9f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03be325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Machine Learning libraries\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "# helper preprocessing module\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7124dff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = w.get_clean_steamspy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d752cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>owners</th>\n",
       "      <th>average_forever</th>\n",
       "      <th>average_2weeks</th>\n",
       "      <th>median_forever</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_Software Training</th>\n",
       "      <th>Genre_ Game Development</th>\n",
       "      <th>Genre_ Audio Production</th>\n",
       "      <th>Genre_ Web Publishing</th>\n",
       "      <th>Genre_Design &amp; Illustration</th>\n",
       "      <th>Genre_Game Development</th>\n",
       "      <th>Genre_ Movie</th>\n",
       "      <th>Genre_ Education</th>\n",
       "      <th>Genre_ Software Training</th>\n",
       "      <th>Genre_Early Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063730</td>\n",
       "      <td>New World</td>\n",
       "      <td>Amazon_Games</td>\n",
       "      <td>Amazon_Games</td>\n",
       "      <td>174544</td>\n",
       "      <td>75536</td>\n",
       "      <td>50,000,000 .. 100,000,000</td>\n",
       "      <td>137.616667</td>\n",
       "      <td>24.233333</td>\n",
       "      <td>59.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>271590</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>Rockstar_North</td>\n",
       "      <td>Rockstar_Games</td>\n",
       "      <td>1274695</td>\n",
       "      <td>215866</td>\n",
       "      <td>50,000,000 .. 100,000,000</td>\n",
       "      <td>225.833333</td>\n",
       "      <td>11.383333</td>\n",
       "      <td>95.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>550</td>\n",
       "      <td>Left 4 Dead 2</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>684284</td>\n",
       "      <td>17474</td>\n",
       "      <td>20,000,000 .. 50,000,000</td>\n",
       "      <td>40.166667</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>252490</td>\n",
       "      <td>Rust</td>\n",
       "      <td>Facepunch_Studios</td>\n",
       "      <td>Facepunch_Studios</td>\n",
       "      <td>764911</td>\n",
       "      <td>115754</td>\n",
       "      <td>10,000,000 .. 20,000,000</td>\n",
       "      <td>372.050000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>52.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>Facepunch_Studios</td>\n",
       "      <td>Valve</td>\n",
       "      <td>892193</td>\n",
       "      <td>30808</td>\n",
       "      <td>20,000,000 .. 50,000,000</td>\n",
       "      <td>197.316667</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>23.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      appid                name          developer          publisher  \\\n",
       "3   1063730           New World       Amazon_Games       Amazon_Games   \n",
       "5    271590  Grand Theft Auto V     Rockstar_North     Rockstar_Games   \n",
       "7       550       Left 4 Dead 2              Valve              Valve   \n",
       "9    252490                Rust  Facepunch_Studios  Facepunch_Studios   \n",
       "11     4000         Garry's Mod  Facepunch_Studios              Valve   \n",
       "\n",
       "    positive  negative                     owners  average_forever  \\\n",
       "3     174544     75536  50,000,000 .. 100,000,000       137.616667   \n",
       "5    1274695    215866  50,000,000 .. 100,000,000       225.833333   \n",
       "7     684284     17474   20,000,000 .. 50,000,000        40.166667   \n",
       "9     764911    115754   10,000,000 .. 20,000,000       372.050000   \n",
       "11    892193     30808   20,000,000 .. 50,000,000       197.316667   \n",
       "\n",
       "    average_2weeks  median_forever  ...  Genre_Software Training  \\\n",
       "3        24.233333       59.450000  ...                    False   \n",
       "5        11.383333       95.016667  ...                    False   \n",
       "7         4.616667        8.900000  ...                    False   \n",
       "9        22.800000       52.600000  ...                    False   \n",
       "11        7.533333       23.766667  ...                    False   \n",
       "\n",
       "    Genre_ Game Development  Genre_ Audio Production  Genre_ Web Publishing  \\\n",
       "3                     False                    False                  False   \n",
       "5                     False                    False                  False   \n",
       "7                     False                    False                  False   \n",
       "9                     False                    False                  False   \n",
       "11                    False                    False                  False   \n",
       "\n",
       "    Genre_Design & Illustration  Genre_Game Development Genre_ Movie  \\\n",
       "3                         False                   False        False   \n",
       "5                         False                   False        False   \n",
       "7                         False                   False        False   \n",
       "9                         False                   False        False   \n",
       "11                        False                   False        False   \n",
       "\n",
       "   Genre_ Education Genre_ Software Training Genre_Early Access  \n",
       "3             False                    False              False  \n",
       "5             False                    False              False  \n",
       "7             False                    False              False  \n",
       "9             False                    False              False  \n",
       "11            False                    False              False  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d451df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appid', 'name', 'developer', 'publisher', 'positive', 'negative',\n",
       "       'owners', 'average_forever', 'average_2weeks', 'median_forever',\n",
       "       ...\n",
       "       'Genre_Software Training', 'Genre_ Game Development',\n",
       "       'Genre_ Audio Production', 'Genre_ Web Publishing',\n",
       "       'Genre_Design & Illustration', 'Genre_Game Development', 'Genre_ Movie',\n",
       "       'Genre_ Education', 'Genre_ Software Training', 'Genre_Early Access'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2541d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = w.my_train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215b0ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moderately_played    1222\n",
       "heavily_played         65\n",
       "rarely_played          31\n",
       "Name: binned_hours, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.binned_hours.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff22df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, validate, test = m.prep_for_model(df, train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9883c3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_validate, y_validate, x_test, y_test = m.isolate_target(train,validate,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2734dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4efc9",
   "metadata": {},
   "source": [
    "## Decision-Tree Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    '''\n",
    "    This function initializes a dataframe, and lists for scoring\n",
    "    the models used for the project.\n",
    "    '''\n",
    "    depth_list = []\n",
    "    sample_list = []\n",
    "    c_val_list = []\n",
    "    for x in range(1,21,1):\n",
    "        depth_list.append(x)\n",
    "    for x in range(1,21,1):\n",
    "        sample_list.append(x)\n",
    "    for x in range(5,100,5):\n",
    "        c_val_list.append(x/100)\n",
    "\n",
    "    \n",
    "    scores = pd.DataFrame(columns=['model_name', 'train_score', 'validate_score', 'score_difference'])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a04c687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58dd1068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, train_score, validate_score, score_difference]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_list = []\n",
    "sample_list = []\n",
    "c_val_list = []\n",
    "for x in range(1,21,1):\n",
    "    depth_list.append(x)\n",
    "for x in range(1,21,1):\n",
    "    sample_list.append(x)\n",
    "for x in range(5,100,5):\n",
    "    c_val_list.append(x/100)\n",
    "\n",
    "#%%\n",
    "scores = pd.DataFrame(columns=['model_name', 'train_score', 'validate_score', 'score_difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9446291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_results(x_train, y_train, x_validate, y_validate, scores):\n",
    "    '''\n",
    "    For \n",
    "    '''\n",
    "    \n",
    "    DTC_parameters = {'max_depth':depth_list}\n",
    "    #%%\n",
    "    DTC = DecisionTreeClassifier(random_state=142)\n",
    "    #%%\n",
    "    cv = 5\n",
    "    #%%\n",
    "    grid_DTC = GridSearchCV(estimator=DTC, param_grid=DTC_parameters, cv=cv, n_jobs=-1)\n",
    "    #%%\n",
    "    grid_DTC.fit(x_train, y_train)\n",
    "    train_score = grid_DTC.best_estimator_.score(x_train, y_train)\n",
    "    validate_score = grid_DTC.best_estimator_.score(x_validate, y_validate)\n",
    "    #%%\n",
    "    print(f'Best parameters per algorithm:')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f'Decision Tree Parameters:  {grid_DTC.best_params_}')\n",
    "    \n",
    "    scores.loc[len(scores)] = ['Decision Tree', train_score, validate_score, train_score - validate_score]\n",
    "    \n",
    "    y_preds_train = pd.DataFrame({\n",
    "        'y_act': y_train,\n",
    "        'baseline': 92,\n",
    "        'DTC': grid_DTC.predict(x_train)})\n",
    "    y_preds_validate = pd.DataFrame({\n",
    "        'y_act': y_validate,\n",
    "        'baseline': 92,\n",
    "        'DTC': grid_DTC.predict(x_validate)})\n",
    "    print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.DTC, output_dict=True)))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ce0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_decision_tree_results(x_train, y_train, x_validate, y_validate, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f52294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.recall_score, average = 'macro')\n",
    "#gs_svc = GridSearchCV(estimator=svc_clf,param_grid=param_grid,scoring=scorer,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "facd0ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters per algorithm:\n",
      "----------------------------------------------------\n",
      "Decision Tree Parameters:  {'max_depth': 18}\n"
     ]
    }
   ],
   "source": [
    "DTC_parameters = {'max_depth':depth_list}\n",
    "#%%\n",
    "DTC = DecisionTreeClassifier(random_state=142)\n",
    "#%%\n",
    "cv = 5\n",
    "#%%\n",
    "grid_DTC = GridSearchCV(estimator=DTC, param_grid=DTC_parameters, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "#%%\n",
    "grid_DTC.fit(x_train, y_train)\n",
    "train_score = grid_DTC.best_estimator_.score(x_train, y_train)\n",
    "validate_score = grid_DTC.best_estimator_.score(x_validate, y_validate)\n",
    "#%%\n",
    "print(f'Best parameters per algorithm:')\n",
    "print('----------------------------------------------------')\n",
    "print(f'Decision Tree Parameters:  {grid_DTC.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5285b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.loc[len(scores)] = ['Decision Tree', train_score, validate_score, train_score - validate_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d8c99d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.955235</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  train_score  validate_score  score_difference\n",
       "0  Decision Tree     0.955235        0.922727          0.032508"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e95a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           heavily_played  moderately_played  rarely_played  accuracy  \\\n",
      "precision        0.250000           0.939535            0.0  0.922727   \n",
      "recall           0.117647           0.980583            0.0  0.922727   \n",
      "f1-score         0.160000           0.959620            0.0  0.922727   \n",
      "support         17.000000         412.000000           11.0  0.922727   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.396512      0.889405  \n",
      "recall       0.366077      0.922727  \n",
      "f1-score     0.373207      0.904735  \n",
      "support    440.000000    440.000000  \n"
     ]
    }
   ],
   "source": [
    "y_preds_train = pd.DataFrame({\n",
    "    'y_act': y_train,\n",
    "    'baseline': 92,\n",
    "    'DTC': grid_DTC.predict(x_train)})\n",
    "y_preds_validate = pd.DataFrame({\n",
    "    'y_act': y_validate,\n",
    "    'baseline': 92,\n",
    "    'DTC': grid_DTC.predict(x_validate)})\n",
    "print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.DTC, output_dict=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409a9cd",
   "metadata": {},
   "source": [
    "## RF Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7b4b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_results(x_train, y_train, x_validate, y_validate, scores):\n",
    "    \n",
    "    RF_parameters = {'max_depth':depth_list}\n",
    "    #%%\n",
    "    RF = RandomForestClassifier(random_state=142)\n",
    "    #%%\n",
    "    cv = 5\n",
    "    #%%\n",
    "    grid_RF = GridSearchCV(estimator=RF, param_grid=RF_parameters, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "    #%%\n",
    "    grid_RF.fit(x_train, y_train)\n",
    "    train_score = grid_RF.best_estimator_.score(x_train, y_train)\n",
    "    validate_score = grid_RF.best_estimator_.score(x_validate, y_validate)\n",
    "    #%%\n",
    "    print(f'Best parameters per algorithm:')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f'Random Forest Parameters:  {grid_RF.best_params_}')\n",
    "    \n",
    "    scores.loc[len(scores)] = ['Random Forest', train_score, validate_score, train_score - validate_score]\n",
    "    \n",
    "    y_preds_train = pd.DataFrame({\n",
    "        'y_act': y_train,\n",
    "        'baseline': 92,\n",
    "        'RF': grid_RF.predict(x_train)})\n",
    "    y_preds_validate = pd.DataFrame({\n",
    "        'y_act': y_validate,\n",
    "        'baseline': 92,\n",
    "        'RF': grid_RF.predict(x_validate)})\n",
    "    print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.RF, output_dict=True)))\n",
    "\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3359de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters per algorithm:\n",
      "----------------------------------------------------\n",
      "Random Forest Parameters:  {'max_depth': 14}\n"
     ]
    }
   ],
   "source": [
    "RF_parameters = {'max_depth':depth_list}\n",
    "#%%\n",
    "RF = RandomForestClassifier(random_state=142)\n",
    "#%%\n",
    "cv = 5\n",
    "#%%\n",
    "grid_RF = GridSearchCV(estimator=RF, param_grid=RF_parameters, cv=cv, n_jobs=-1)\n",
    "#%%\n",
    "grid_RF.fit(x_train, y_train)\n",
    "train_score = grid_RF.best_estimator_.score(x_train, y_train)\n",
    "validate_score = grid_RF.best_estimator_.score(x_validate, y_validate)\n",
    "#%%\n",
    "print(f'Best parameters per algorithm:')\n",
    "print('----------------------------------------------------')\n",
    "print(f'Random Forest Parameters:  {grid_RF.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37779966",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.loc[len(scores)] = ['Random Forest', train_score, validate_score, train_score - validate_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15b584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.955235</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.020382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  train_score  validate_score  score_difference\n",
       "0  Decision Tree     0.955235        0.922727          0.032508\n",
       "1  Random Forest     0.952200        0.931818          0.020382"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ea2633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           heavily_played  moderately_played  rarely_played  accuracy  \\\n",
      "precision        0.333333           0.940092            0.0  0.931818   \n",
      "recall           0.117647           0.990291            0.0  0.931818   \n",
      "f1-score         0.173913           0.964539            0.0  0.931818   \n",
      "support         17.000000         412.000000           11.0  0.931818   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.424475      0.893147  \n",
      "recall       0.369313      0.931818  \n",
      "f1-score     0.379484      0.909879  \n",
      "support    440.000000    440.000000  \n"
     ]
    }
   ],
   "source": [
    "y_preds_train = pd.DataFrame({\n",
    "    'y_act': y_train,\n",
    "    'baseline': 92,\n",
    "    'RF': grid_RF.predict(x_train)})\n",
    "y_preds_validate = pd.DataFrame({\n",
    "    'y_act': y_validate,\n",
    "    'baseline': 92,\n",
    "    'RF': grid_RF.predict(x_validate)})\n",
    "print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.RF, output_dict=True)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee8fc5",
   "metadata": {},
   "source": [
    "## KNN modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89118c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_results(x_train, y_train, x_validate, y_validate, scores):\n",
    "    \n",
    "    KNN_parameters = {'n_neighbors':[1,2,3,4,5]}\n",
    "    #%%\n",
    "    KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "    #%%\n",
    "    cv = 5\n",
    "    #%%\n",
    "    grid_KNN = GridSearchCV(estimator=KNN, param_grid=KNN_parameters, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "    #%%\n",
    "    grid_KNN.fit(x_train, y_train)\n",
    "    train_score = grid_KNN.best_estimator_.score(x_train, y_train)\n",
    "    validate_score = grid_KNN.best_estimator_.score(x_validate, y_validate)\n",
    "    #%%\n",
    "    print(f'Best parameters per algorithm:')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f'KNN Parameters:  {grid_KNN.best_params_}')\n",
    "    \n",
    "    scores.loc[len(scores)] = ['KNN', train_score, validate_score, train_score - validate_score]\n",
    "    \n",
    "    y_preds_train = pd.DataFrame({\n",
    "        'y_act': y_train,\n",
    "        'baseline': 92,\n",
    "        'KNN': grid_KNN.predict(x_train)})\n",
    "    y_preds_validate = pd.DataFrame({\n",
    "        'y_act': y_validate,\n",
    "        'baseline': 92,\n",
    "        'KNN': grid_KNN.predict(x_validate)})\n",
    "    print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.KNN, output_dict=True)))\n",
    "\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e04472a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters per algorithm:\n",
      "----------------------------------------------------\n",
      "KNN Parameters:  {'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "KNN_parameters = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10]}\n",
    "#%%\n",
    "KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform') #KNearestNeighbors(random_state=142)\n",
    "#%%\n",
    "cv = 5\n",
    "#%%\n",
    "grid_KNN = GridSearchCV(estimator=KNN, param_grid=KNN_parameters, cv=cv, n_jobs=-1)\n",
    "#%%\n",
    "grid_KNN.fit(x_train, y_train)\n",
    "train_score = grid_KNN.best_estimator_.score(x_train, y_train)\n",
    "validate_score = grid_KNN.best_estimator_.score(x_validate, y_validate)\n",
    "#%%\n",
    "print(f'Best parameters per algorithm:')\n",
    "print('----------------------------------------------------')\n",
    "print(f'KNN Parameters:  {grid_KNN.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea687e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92994307",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.loc[len(scores)] = ['KNN', train_score, validate_score, train_score - validate_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a07addd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.955235</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.935508</td>\n",
       "      <td>0.940909</td>\n",
       "      <td>-0.005401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  train_score  validate_score  score_difference\n",
       "0  Decision Tree     0.955235        0.922727          0.032508\n",
       "1  Random Forest     0.952200        0.931818          0.020382\n",
       "2            KNN     0.935508        0.940909         -0.005401"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "649f44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           heavily_played  moderately_played  rarely_played  accuracy  \\\n",
      "precision        1.000000           0.940639            0.0  0.940909   \n",
      "recall           0.117647           1.000000            0.0  0.940909   \n",
      "f1-score         0.210526           0.969412            0.0  0.940909   \n",
      "support         17.000000         412.000000           11.0  0.940909   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.646880      0.919417  \n",
      "recall       0.372549      0.940909  \n",
      "f1-score     0.393313      0.915856  \n",
      "support    440.000000    440.000000  \n"
     ]
    }
   ],
   "source": [
    "y_preds_train = pd.DataFrame({\n",
    "    'y_act': y_train,\n",
    "    'baseline': 92,\n",
    "    'KNN': grid_KNN.predict(x_train)})\n",
    "y_preds_validate = pd.DataFrame({\n",
    "    'y_act': y_validate,\n",
    "    'baseline': 92,\n",
    "    'KNN': grid_KNN.predict(x_validate)})\n",
    "print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.KNN, output_dict=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e9038",
   "metadata": {},
   "source": [
    "## LogReg Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99ada811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_reg_results(x_train, y_train, x_validate, y_validate, scores):\n",
    "    \n",
    "    LR_parameters = {'C':c_val_list}\n",
    "    #%%\n",
    "    LR = LogisticRegression(solver='liblinear')\n",
    "    #%%\n",
    "    cv = 5\n",
    "    #%%\n",
    "    grid_LR = GridSearchCV(estimator=LR, param_grid=LR_parameters, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "    #%%\n",
    "    grid_LR.fit(x_train, y_train)\n",
    "    train_score = grid_LR.best_estimator_.score(x_train, y_train)\n",
    "    validate_score = grid_LR.best_estimator_.score(x_validate, y_validate)\n",
    "    #%%\n",
    "    print(f'Best parameters per algorithm:')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f'LR Parameters:  {grid_LR.best_params_}')\n",
    "    \n",
    "    scores.loc[len(scores)] = ['LR', train_score, validate_score, train_score - validate_score]\n",
    "    \n",
    "    y_preds_train = pd.DataFrame({\n",
    "        'y_act': y_train,\n",
    "        'baseline': 92,\n",
    "        'LR': grid_LR.predict(x_train)})\n",
    "    y_preds_validate = pd.DataFrame({\n",
    "        'y_act': y_validate,\n",
    "        'baseline': 92,\n",
    "        'LR': grid_LR.predict(x_validate)})\n",
    "    print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.LR, output_dict=True)))\n",
    "\n",
    "\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72012482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters per algorithm:\n",
      "----------------------------------------------------\n",
      "LR Parameters:  {'C': 0.9}\n"
     ]
    }
   ],
   "source": [
    "LR_parameters = {'C':c_val_list}\n",
    "#%%\n",
    "LR = LogisticRegression(solver='liblinear') #KNearestNeighbors(random_state=142)\n",
    "#%%\n",
    "cv = 5\n",
    "#%%\n",
    "grid_LR = GridSearchCV(estimator=LR, param_grid=LR_parameters, cv=cv, n_jobs=-1)\n",
    "#%%\n",
    "grid_LR.fit(x_train, y_train)\n",
    "train_score = grid_LR.best_estimator_.score(x_train, y_train)\n",
    "validate_score = grid_LR.best_estimator_.score(x_validate, y_validate)\n",
    "#%%\n",
    "print(f'Best parameters per algorithm:')\n",
    "print('----------------------------------------------------')\n",
    "print(f'LR Parameters:  {grid_LR.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97d68208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d192a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.loc[len(scores)] = ['LR', train_score, validate_score, train_score - validate_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eef61441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.955235</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.935508</td>\n",
       "      <td>0.940909</td>\n",
       "      <td>-0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.931715</td>\n",
       "      <td>0.938636</td>\n",
       "      <td>-0.006922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  train_score  validate_score  score_difference\n",
       "0  Decision Tree     0.955235        0.922727          0.032508\n",
       "1  Random Forest     0.952200        0.931818          0.020382\n",
       "2            KNN     0.935508        0.940909         -0.005401\n",
       "3             LR     0.931715        0.938636         -0.006922"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79c2d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           heavily_played  moderately_played  rarely_played  accuracy  \\\n",
      "precision        1.000000           0.938497            0.0  0.938636   \n",
      "recall           0.058824           1.000000            0.0  0.938636   \n",
      "f1-score         0.111111           0.968273            0.0  0.938636   \n",
      "support         17.000000         412.000000           11.0  0.938636   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.646166      0.917410  \n",
      "recall       0.352941      0.938636  \n",
      "f1-score     0.359795      0.910948  \n",
      "support    440.000000    440.000000  \n"
     ]
    }
   ],
   "source": [
    "y_preds_train = pd.DataFrame({\n",
    "    'y_act': y_train,\n",
    "    'baseline': 92,\n",
    "    'LR': grid_LR.predict(x_train)})\n",
    "y_preds_validate = pd.DataFrame({\n",
    "    'y_act': y_validate,\n",
    "    'baseline': 92,\n",
    "    'LR': grid_LR.predict(x_validate)})\n",
    "print(pd.DataFrame(classification_report(y_preds_validate.y_act, y_preds_validate.LR, output_dict=True)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9be4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20dde6fa",
   "metadata": {},
   "source": [
    "## KNN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1579aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_test(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    \n",
    "    scores = pd.DataFrame(columns=['model_name', 'train_score', 'test_score', 'score_difference'])\n",
    "    \n",
    "    KNN_parameters = {'n_neighbors':[1,2,3,4,5]}\n",
    "    \n",
    "    KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "    \n",
    "    cv = 5\n",
    "    \n",
    "    grid_KNN = GridSearchCV(estimator=KNN, param_grid=KNN_parameters, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    grid_KNN.fit(x_train, y_train)\n",
    "    train_score = grid_KNN.best_estimator_.score(x_train, y_train)\n",
    "    test_score = grid_KNN.best_estimator_.score(x_test, y_test)\n",
    "    \n",
    "    print(f'Best parameters per algorithm:')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f'KNN Parameters:  {grid_KNN.best_params_}')\n",
    "\n",
    "    scores.loc[len(scores)] = ['KNN', train_score, test_score, train_score - test_score]\n",
    "\n",
    "    y_preds_train = pd.DataFrame({\n",
    "        'y_act': y_train,\n",
    "        'baseline': 92,\n",
    "        'KNN': grid_KNN.predict(x_train)})\n",
    "    y_preds_test = pd.DataFrame({\n",
    "        'y_act': y_test,\n",
    "        'baseline': 92,\n",
    "        'KNN': grid_KNN.predict(x_test)})\n",
    "    print(pd.DataFrame(classification_report(y_preds_test.y_act, y_preds_test.KNN, output_dict=True)))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4223ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns=['model_name', 'train_score', 'test_score', 'score_difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd53878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, train_score, test_score, score_difference]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "549b49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters per algorithm:\n",
      "----------------------------------------------------\n",
      "KNN Parameters:  {'n_neighbors': 2}\n",
      "           heavily_played  moderately_played  rarely_played  accuracy  \\\n",
      "precision        0.272727           0.933014            0.0       0.9   \n",
      "recall           0.300000           0.960591            0.0       0.9   \n",
      "f1-score         0.285714           0.946602            0.0       0.9   \n",
      "support         20.000000         406.000000           14.0       0.9   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.401914      0.873314  \n",
      "recall       0.420197      0.900000  \n",
      "f1-score     0.410772      0.886442  \n",
      "support    440.000000    440.000000  \n"
     ]
    }
   ],
   "source": [
    "KNN_parameters = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10]}\n",
    "#%%\n",
    "KNN = KNeighborsClassifier(n_neighbors=KNN_parameters, weights='uniform')\n",
    "#%%\n",
    "cv = 5\n",
    "#%%\n",
    "grid_KNN = GridSearchCV(estimator=KNN, param_grid=KNN_parameters, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "#%%\n",
    "grid_KNN.fit(x_train, y_train)\n",
    "train_score = grid_KNN.best_estimator_.score(x_train, y_train)\n",
    "test_score = grid_KNN.best_estimator_.score(x_test, y_test)\n",
    "    #%%\n",
    "print(f'Best parameters per algorithm:')\n",
    "print('----------------------------------------------------')\n",
    "print(f'KNN Parameters:  {grid_KNN.best_params_}')\n",
    "    \n",
    "scores.loc[len(scores)] = ['KNN', train_score, test_score, train_score - test_score]\n",
    "    \n",
    "y_preds_train = pd.DataFrame({\n",
    "    'y_act': y_train,\n",
    "    'baseline': 92,\n",
    "    'KNN': grid_KNN.predict(x_train)})\n",
    "y_preds_test = pd.DataFrame({\n",
    "    'y_act': y_test,\n",
    "    'baseline': 92,\n",
    "    'KNN': grid_KNN.predict(x_test)})\n",
    "print(pd.DataFrame(classification_report(y_preds_test.y_act, y_preds_test.KNN, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "551535e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>score_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.92261</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.02261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.92261</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.02261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  train_score  test_score  score_difference\n",
       "0        KNN      0.92261         0.9           0.02261\n",
       "1        KNN      0.92261         0.9           0.02261"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce55bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
